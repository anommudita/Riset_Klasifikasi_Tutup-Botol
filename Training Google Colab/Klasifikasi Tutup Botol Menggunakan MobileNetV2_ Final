{"cells":[{"cell_type":"markdown","metadata":{"id":"license"},"source":["##### *Copyright 2024*"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"rKwqeqWBXANA"},"outputs":[],"source":["# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"hRTa3Ee15WsJ"},"source":["# Klasifikasi Tutup Botol Menggunakan Arsitektur MobileNEtV2"]},{"cell_type":"markdown","metadata":{"id":"TaX0smDP7xQY"},"source":["Sebelumnya, nama saya Ida Bagus Anom Mudita, Mahasiswa dari Universitas Pendidikan Ganesha. Di Projek Google colab ini saya membuat klasifikasi tutup botol berdasarkan warna dan label menggunakan MobileNetV2 yang nanti akan diterapkan atau diimplementasikan di mini komputer atau perangkat yang saya gunakan ialah Raspberry Pi 4. Projek ini merupakan karya akhir untuk persyaratan kelulusan S1 maka dari itu harus penuh semangat membuatnya heheh.\n","\n","Jika kalian ingin mencobanya, kalian harus memahami materi tentang **Supervised Learning**, **Neural Network**, **Convotional Neural Network**, **Deep Learning**, **MobileNetV2**, dan **Hyperparameter**, **Loss Function**, **Fungsi Aktivasi**. Setelah itu baru kalian boleh mencoba projek ini agar kalian tidak bingung mempelajarinya, ohh jangan lupa bisa ngoding Python nya:)\n","\n","\n","Dibawah ini saya menjelaskan tahapan-tahapan training secara komprehensif\n","dan versi python yang digunakan 3.10 serta versi tensorflow diatas 2.3 (konversi model ke format tfllite)\n","\n","Referensi dari projek ini :\n","\n","( [retrain classification ](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf1.ipynb).)\n","\n","( [waste classification ](https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf1.ipynb).)\n"]},{"cell_type":"markdown","metadata":{"id":"viewin-badges"},"source":["<a href=\"https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"></a>\n","&nbsp;&nbsp;&nbsp;&nbsp;\n","<a href=\"https://github.com/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\" target=\"_parent\"><img src=\"https://img.shields.io/static/v1?logo=GitHub&label=&color=333333&style=flat&message=View%20on%20GitHub\" alt=\"View in GitHub\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"BnSreNhbCQ69"},"source":["Untuk memulai menjalan semua code ini, cari menu **Runtime > Jalankan Semua** di Colab toolbar"]},{"cell_type":"markdown","metadata":{"id":"GTCYQg_be8C0"},"source":["## Import library yang dibutuhkan!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBMcobPHdD8O"},"outputs":[],"source":["from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import layers, models\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from tensorflow.keras.applications import Xception\n","from tensorflow.keras.optimizers import Adam\n","import os\n","import csv\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n","import seaborn as sns\n","from sklearn.model_selection import KFold\n","import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import CSVLogger\n","from time import *\n","\n","\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)\n","# Muat model MobileNetV2\n","model = Xception(weights='imagenet')\n","print(\"MobileNetV2 input shape:\", model.input_shape)\n","\n","model1 = MobileNetV2(weights='imagenet')\n","print(\"MobileNetV2 input shape:\", model1.input_shape)\n","!python --version\n","\n"]},{"cell_type":"markdown","metadata":{"id":"v77rlkCKW0IJ"},"source":["## Persiapan training data\n"]},{"cell_type":"markdown","source":["Untuk meletakan dataset di google colab sebaiknya diletekan terlebih dahulu dataset di drive kalian, agar kedepan ketika google colab terputus koneksi bisa dihubungan dengan grive dan lebih cepat salin datanya.\n","\n","\n","gdrive kalian letakan file berikut:\n","1. dataset_final.zip ==> data subset\n","2. dataset_final_kfold.zip == data kfold luar dari data testing\n","3. class.txt"],"metadata":{"id":"J-jjlLngPVQW"}},{"cell_type":"markdown","source":["Login akun gmail kalian yang sudah menyimpan dataset di drive"],"metadata":{"id":"KjZ6ZID7e7_M"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0R6s87MiC36G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["copy file dataset_final.zip, dataset_final_kfold.zip dan class.txt dari drive (directory content) ke menunjuk dir utama google colab"],"metadata":{"id":"Z3270i87P8wS"}},{"cell_type":"code","source":["!cp drive/MyDrive/dataset/dataset_final.zip /content\n","!cp drive/MyDrive/dataset/dataset_final_kfold.zip /content\n","!cp drive/MyDrive/dataset/class.txt /content"],"metadata":{"id":"A_V57_CmY-MK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["unzip file dari format zip"],"metadata":{"id":"tHBp1qtQhAjI"}},{"cell_type":"code","source":["!unzip -q dataset_final.zip\n","!unzip -q dataset_final_kfold.zip"],"metadata":{"id":"OLNYcIK2EBw6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cara menghapus file atau folder di google colab jika terjadi kesalahan mencopy data"],"metadata":{"id":"rIUEGazvQdz1"}},{"cell_type":"code","source":["!rm -rf /content/dataset_final.zip"],"metadata":{"id":"QzlhCs3chTXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training Data Menggunakan MobileNetV2 menggunakan EarlyStopiing"],"metadata":{"id":"BXv4idCNhc7X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCLb_yV5JfF3"},"outputs":[],"source":["# early stopping\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import CSVLogger\n","import time\n","\n","# fungsi menyiapkan data train/validation/test\n","def data_load(data_dir, img_height, img_width, batch_size):\n","\n","    # data train\n","    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","    # Flow dari direktori dengan generator\n","    train_generator = train_datagen.flow_from_directory(\n","        directory= data_dir +'train',\n","        # subset=\"training\",\n","        target_size=(img_height, img_width),\n","        color_mode='rgb',\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        shuffle=True\n","    )\n","\n","    # data validation\n","    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","    # Flow dari direktori dengan generator\n","    val_generator = val_datagen.flow_from_directory(\n","        directory= data_dir +'val',\n","        # subset=\"validation\",\n","        target_size=(img_height, img_width),\n","        color_mode='rgb',\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        shuffle=True\n","    )\n","\n","    # data test\n","    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","    # Flow dari direktori dengan generator\n","    test_generator = test_datagen.flow_from_directory(\n","        directory= data_dir +'test',\n","        # subset=\"test\",\n","        target_size=(img_height, img_width),\n","        color_mode='rgb',\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        shuffle=True\n","    )\n","\n","    # Dapatkan kamus nama kelas dari test generator\n","    class_dict = train_generator.class_indices\n","    # Tampilkan nama-nama kelas dan key\n","    class_names = list(class_dict.keys())\n","\n","    print(train_generator)\n","    print(val_generator)\n","    print(test_generator)\n","\n","    return train_generator, val_generator, test_generator, class_names\n","\n","\n","# fungsi menyiapkan model mobilenetV2\n","def model_load(IMG_SHAPE=(224, 224, 3), class_num=13):\n","\n","    # Muat model MobileNetV2 yang telah dilatih sebelumnya tanpa lapisan atas (top)\n","    #base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n","\n","    # jika menggunakna model Xception bisa menggunakna code dibawah ini\n","    base_model = Xception(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n","\n","    # Membekukan lapisan base model sehingga tidak akan dilatih ulang\n","    base_model.trainable = False\n","\n","    # Menambahkan Global Average Pooling\n","    x = GlobalAveragePooling2D()(base_model.output)\n","\n","    # Menambahkan lapisan Dense dengan aktivasi Softmax untuk klasifikasi 13 kelas\n","    output_layer = Dense(class_num, activation='softmax')(x)\n","\n","    #mobilenetV2(Feature Map) dan Output layer FC menggunakan softmax\n","    model = Model(inputs=base_model.input, outputs=output_layer)\n","    # Menampilkan arsitektur model\n","    model.summary()\n","\n","    optimizer = Adam(learning_rate=0.001)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# fungsi untuk membuat tampian grafik\n","def show_loss_acc(history):\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    plt.figure(figsize=(8, 8))\n","    plt.subplot(2, 1, 1)\n","    plt.plot(acc, label='Training Accuracy')\n","    plt.plot(val_acc, label='Validation Accuracy')\n","    plt.legend(loc='lower right')\n","    plt.ylabel('Accuracy')\n","    plt.ylim([min(plt.ylim()), 1])\n","    plt.title('Training and Validation Accuracy')\n","\n","    plt.subplot(2, 1, 2)\n","    plt.plot(loss, label='Training Loss')\n","    plt.plot(val_loss, label='Validation Loss')\n","    plt.legend(loc='upper right')\n","    plt.ylabel('Cross Entropy')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('epoch')\n","    plt.savefig('results_grafik.png', dpi=100)\n","\n","\n","# fungsi untuk menkonversi data time menjadi menit\n","def convert_seconds(seconds):\n","    # Menghitung menit dan sisa detik\n","    minutes = seconds // 60\n","    remaining_seconds = seconds % 60\n","    return f\"{int(minutes)} menit {remaining_seconds:.2f} detik\"\n","\n","\n","# fungsi train\n","def train(epochs, batch_sizes):\n","    begin_time = time.time()\n","    train_generator, val_generator, test_generator, class_names = data_load(\"dataset_final/\", 224, 224, 32)\n","    # print jumlah kelas\n","    print(class_names)\n","\n","    # memanggil fungsi model loada\n","    model = model_load(class_num=len(class_names))\n","\n","    # membuat early_stopping\n","    early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=10, verbose=1)\n","\n","    # membuat log traing yang disimpan ke format csv\n","    csv_logger = CSVLogger(f'training_log.csv', append=True)\n","\n","\n","    # traing dimulai\n","    # jika tanpa earlystoping hilangkan parameter callbacks\n","    history = model.fit(train_generator, validation_data=val_generator, batch_size=batch_sizes, epochs=epochs, callbacks=[early_stopping, csv_logger],\n","            verbose=1)\n","\n","    KERAS_MODEL_NAME = \"model_final.h5\"\n","    model.save(KERAS_MODEL_NAME)\n","    convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")\n","\n","    end_time = time.time()\n","    run_time = end_time - begin_time\n","    print('The cycle program runs for the following hours:', run_time, \"s\")  # The duration of the cycle program： 1.4201874732\n","    show_loss_acc(history)\n","\n","\n","    # Contoh penggunaan\n","    seconds = run_time\n","    time_str = convert_seconds(seconds)\n","    print(time_str)\n","\n","    # print test\n","    model = tf.keras.models.load_model(KERAS_MODEL_NAME)\n","    model.summary()\n","\n","    # test_loss, test_acc\n","    loss, accuracy = model.evaluate(test_generator)\n","    print('Mobilenev2 test accuracy :', accuracy)\n","\n","    # menyimpan waktu training dan menyimpan hasil test\n","    with open('training_results_time_test.csv', mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Training Time (s)', 'Test Accuracy', 'Test Loss'])\n","        writer.writerow([time_str , accuracy, loss])\n","\n","    # conversi menjadi tflite\n","    TF_LITE_MODEL_FILE_NAME = \"model_final.tflite\"\n","\n","    # tf ke format standar float32\n","    tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    tflite_model = tf_lite_converter.convert()\n","\n","    tflite_model_name = TF_LITE_MODEL_FILE_NAME\n","    open(tflite_model_name, \"wb\").write(tflite_model)\n","    convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")\n","\n","# fungsi untuk (pendukung konversi)\n","def get_file_size(file_path):\n","    size = os.path.getsize(file_path)\n","    return size\n","\n","# funsi convert byte (pendukung konversi)\n","def convert_bytes(size, unit=None):\n","    if unit == \"KB\":\n","        return print('File size ' + str(round(size / 1024, 3)) + 'Kilobytes')\n","    elif unit == \"MB\":\n","        return print('File size ' + str(round(size / 1024 * 1024, 3)) + 'Megabytes')\n","    else :\n","        return print('File size ' + str(round(size)) + 'bytes')\n","\n","if __name__ == '__main__':\n","    train(epochs=100, batch_sizes=32)"]},{"cell_type":"markdown","source":["Training menggunakan data cross kfold validation\n","\n"],"metadata":{"id":"9n1aCixMmRvz"}},{"cell_type":"code","source":["# fungsi untuk mengkonversi time menjadi waktu menit\n","def convert_seconds(seconds):\n","    # Menghitung menit dan sisa detik\n","    minutes = seconds // 60\n","    remaining_seconds = seconds % 60\n","    return f\"{int(minutes)} menit {remaining_seconds:.2f} detik\"\n","\n","# fungsi grafik model per kfold\n","def plot_history(histories, fold_no):\n","    for fold in range(fold_no):\n","        acc = histories[fold].history['accuracy']\n","        val_acc = histories[fold].history['val_accuracy']\n","        loss = histories[fold].history['loss']\n","        val_loss = histories[fold].history['val_loss']\n","\n","        epochs_range = range(len(acc))\n","\n","        plt.figure(figsize=(12, 4))\n","        plt.subplot(1, 2, 1)\n","        plt.plot(epochs_range, acc, label='Training Accuracy')\n","        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","        plt.legend(loc='lower right')\n","        plt.title(f'Fold {fold+1} - Training and Validation Accuracy')\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(epochs_range, loss, label='Training Loss')\n","        plt.plot(epochs_range, val_loss, label='Validation Loss')\n","        plt.legend(loc='upper right')\n","        plt.title(f'Fold {fold+1} - Training and Validation Loss')\n","\n","        plt.savefig(f'results_fold_{fold+1}.png', dpi=100)\n","        plt.show()\n","\n","\n","# membuat persiapan model\n","def model_load(IMG_SHAPE=(224, 224, 3), class_num=13):\n","\n","    # Muat model MobileNetV2 yang telah dilatih sebelumnya tanpa lapisan atas (top)\n","    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n","\n","    # Membekukan lapisan base model sehingga tidak akan dilatih ulang\n","    base_model.trainable = False\n","\n","    # Menambahkan Global Average Pooling\n","    x = GlobalAveragePooling2D()(base_model.output)\n","\n","    # Menambahkan lapisan Dense dengan aktivasi Softmax untuk klasifikasi 8 kelas\n","    output_layer = Dense(class_num, activation='softmax')(x)\n","\n","    # Membuat model baru base_model = mobilenetV2(Feature Map) dan Output layer FC menggunakan softmax\n","    model = Model(inputs=base_model.input, outputs=output_layer)\n","\n","    optimizer = Adam(learning_rate=0.001)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","\n","def load_filenames_and_labels(data_dir):\n","    class_names = sorted(os.listdir(data_dir))\n","    filenames = []\n","    labels = []\n","\n","    for class_index, class_name in enumerate(class_names):\n","        class_dir = os.path.join(data_dir, class_name)\n","        for fname in os.listdir(class_dir):\n","            filenames.append(os.path.join(class_dir, fname))\n","            labels.append(class_name)  # Menggunakan class_name sebagai label\n","\n","    return np.array(filenames), np.array(labels), class_names\n","\n","\n","# Training kfold\n","def kfold_training(epochs, batch_size, k=5):\n","    data_dir = 'dataset_final_kfold/'  # Path ke folder dataset Anda\n","\n","    # data test\n","    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","    # Flow dari direktori dengan generator\n","    test_generator = test_datagen.flow_from_directory(\n","        directory= 'dataset_final/'  +'test',\n","        # subset=\"test\",\n","        target_size=(224, 224),\n","        color_mode='rgb',\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        shuffle=True\n","    )\n","\n","    # Load all filenames and labels\n","    filenames, labels, class_names = load_filenames_and_labels(data_dir)\n","    num_classes = len(class_names)\n","\n","    # KFold setup\n","    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n","    fold_no = 1\n","    accuracy_scores = []\n","    histories = []\n","    results = []  # Untuk menyimpan hasil fold\n","\n","    for train_index, val_index in kfold.split(filenames):\n","        print(f'Training fold {fold_no}/{k}...')\n","\n","        # Data generator setup\n","        train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","        val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","        # Membuat subset data berdasarkan indeks K-Fold\n","        train_filenames = filenames[train_index]\n","        val_filenames = filenames[val_index]\n","        train_labels = labels[train_index]\n","        val_labels = labels[val_index]\n","\n","        # Menyimpan dataframe untuk generator\n","        train_df = pd.DataFrame({'filename': train_filenames, 'class': train_labels})\n","        val_df = pd.DataFrame({'filename': val_filenames, 'class': val_labels})\n","\n","        train_generator = train_datagen.flow_from_dataframe(\n","            dataframe=train_df,\n","            x_col='filename',\n","            y_col='class',\n","            target_size=(224, 224),\n","            batch_size=batch_size,\n","            class_mode='categorical'\n","        )\n","\n","        val_generator = val_datagen.flow_from_dataframe(\n","            dataframe=val_df,\n","            x_col='filename',\n","            y_col='class',\n","            target_size=(224, 224),\n","            batch_size=batch_size,\n","            class_mode='categorical'\n","        )\n","\n","        # Load model\n","        model = model_load(IMG_SHAPE=(224, 224, 3), class_num=num_classes)\n","\n","        # Early Stopping\n","        early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=10, verbose=1)\n","        csv_logger = CSVLogger(f'training_log_fold_{fold_no}.csv', append=True)\n","\n","        # Mulai waktu training\n","        start_time = time.time()\n","\n","        # Train the model\n","        history = model.fit(\n","            train_generator,\n","            validation_data=val_generator,\n","            epochs=epochs,\n","            callbacks=[early_stopping, csv_logger],\n","            verbose=1\n","        )\n","\n","        # Akhir waktu training\n","        end_time = time.time()\n","        training_duration = end_time - start_time  # dalam detik\n","\n","        result_train = convert_seconds(training_duration)\n","\n","        # Simpan history untuk plot nanti\n","        histories.append(history)\n","\n","        # Evaluate on validation set\n","        val_loss, val_accuracy = model.evaluate(val_generator)\n","        print(f'Validation accuracy for fold {fold_no}: {val_accuracy}')\n","\n","        test_loss, test_accuracy = model.evaluate(test_generator)\n","        print('Mobilenev2 test accuracy :', test_accuracy)\n","\n","        # Simpan hasil ke dalam list\n","        results.append({\n","            'Fold': fold_no,\n","            'Validation Loss': val_loss,\n","            'Validation Accuracy': val_accuracy,\n","            'Test Loss': test_loss,\n","            'Test Accuracy': test_accuracy,\n","            'Training Duration (s)': result_train # Menambahkan durasi training\n","        })\n","\n","         # Simpan model\n","        keras_model_name = f\"mobilenetV2_epoch_{epochs}_fold_{fold_no}.h5\"\n","        model.save(keras_model_name)\n","\n","        # Konversi ke TFLite\n","        tf_lite_model_name = f\"mobilenetV2_epoch_{epochs}_fold_{fold_no}.tflite\"\n","        tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","        tflite_model = tf_lite_converter.convert()\n","\n","        with open(tf_lite_model_name, \"wb\") as f:\n","            f.write(tflite_model)\n","\n","        print(f'Model saved as {keras_model_name} and converted to {tf_lite_model_name}')\n","\n","        accuracy_scores.append(val_accuracy)\n","        fold_no += 1\n","\n","    # Plot hasil training untuk setiap fold\n","    plot_history(histories, k)\n","\n","    # Calculate average accuracy\n","    average_accuracy = np.mean(accuracy_scores)\n","    print(f'Average accuracy across {k} folds: {average_accuracy}')\n","\n","    # Simpan hasil ke dalam DataFrame\n","    results_df = pd.DataFrame(results)\n","    results_df.to_csv('kfold_results.csv', index=False)\n","    print('Results saved to kfold_results.csv')\n","\n","    return accuracy_scores\n","\n","if __name__ == '__main__':\n","    kfold_training(epochs=100, batch_size=32, k=5)"],"metadata":{"id":"kgvR2c9lmQqJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Confusion Matrix | Classification Report"],"metadata":{"id":"4FEH4YOdoDbA"}},{"cell_type":"code","source":["# Path ke model .tflite\n","model_path = \"mobileneV2_epoch_100.tflite\"\n","\n","# Load model .tflite\n","interpreter = tf.lite.Interpreter(model_path=model_path)\n","interpreter.allocate_tensors()\n","\n","# Dapatkan detail input dan output\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Print informasi input dan output\n","print(\"Input Shape:\", input_details[0]['shape'])\n","print(\"Input Type:\", input_details[0]['dtype'])\n","print(\"Output Shape:\", output_details[0]['shape'])\n","print(\"Output Type:\", output_details[0]['dtype'])\n","\n","# Membaca nama kelas dari file class.txt\n","class_file = 'class.txt'\n","with open(class_file, 'r') as f:\n","    class_names = f.read().splitlines()\n","\n","# Definisikan ImageDataGenerator untuk preprocessing input\n","test_datagen = ImageDataGenerator(rescale=1./255)  # Normalisasi gambar ke rentang [0, 1]\n","\n","# Flow dari direktori dengan generator untuk data test\n","test_generator = test_datagen.flow_from_directory(\n","    directory='dataset_final/test/',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    batch_size=1,  # Set batch_size = 1 untuk mengambil satu gambar pada satu waktu\n","    class_mode='categorical',\n","    shuffle=False  # Urutan data tetap konsisten saat digunakan dalam generator\n",")\n","\n","# List untuk menyimpan hasil prediksi dan label sebenarnya\n","predicted_classes = []\n","true_classes = []\n","\n","# Loop melalui data uji dan lakukan prediksi menggunakan model TensorFlow Lite\n","for i in range(len(test_generator)):\n","    batch_images, batch_labels = test_generator[i]\n","\n","    # Atur tensor input untuk interpreter\n","    interpreter.set_tensor(input_details[0]['index'], batch_images)\n","\n","    # Jalankan inferensi\n","    interpreter.invoke()\n","\n","    # Ambil hasil output\n","    output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","    # Ambil prediksi kelas dengan probabilitas tertinggi\n","    predictions = np.argmax(output_data, axis=1)\n","\n","    # Simpan hasil prediksi dan label sebenarnya\n","    predicted_classes.extend(predictions)\n","    true_classes.extend(np.argmax(batch_labels, axis=1))\n","\n","# Menghitung matriks kebingungan\n","print(\"true class :\", true_classes)\n","print(\"predicted class :\", predicted_classes)\n","\n","cm = confusion_matrix(true_classes, predicted_classes)\n","\n","# Membuat plot matriks kebingungan\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n","\n","\n","sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\", cbar=False)\n","\n","# Rotate the x-axis and y-axis labels to ensure they fit and are readable\n","plt.xticks(rotation=45, ha=\"right\", fontsize=12)  # Rotate x-axis labels for better readability\n","plt.yticks(rotation=0, fontsize=12)  # Keep y-axis labels horizontal\n","\n","plt.ylabel('True Label', fontsize=13)\n","plt.xlabel('Prediction Label', fontsize=13)\n","plt.title('Confusion Matrix', fontsize=17)\n","plt.savefig('confusion_matrix_final.png')\n","plt.show()\n","\n","# Generate classification report with precision, recall, f1-score (including macro, micro, and weighted averages)\n","classification_report_str = classification_report(true_classes, predicted_classes, target_names=class_names, digits=4)\n","print(\"Classification Report:\\n\", classification_report_str)\n","\n","# Save classification report to a text file\n","with open('classification_report.txt', 'w') as report_file:\n","    report_file.write(classification_report_str)\n","\n","# Menghitung metrik evaluasi untuk setiap kelas (tanpa rata-rata makro/mikro untuk presisi, recall, dan F1)\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","precision = precision_score(true_classes, predicted_classes, average=None)\n","recall = recall_score(true_classes, predicted_classes, average=None)\n","f1 = f1_score(true_classes, predicted_classes, average=None)\n","\n","# Add macro, micro, and weighted metrics for precision, recall, F1\n","precision_macro = precision_score(true_classes, predicted_classes, average='macro')\n","recall_macro = recall_score(true_classes, predicted_classes, average='macro')\n","f1_macro = f1_score(true_classes, predicted_classes, average='macro')\n","\n","precision_micro = precision_score(true_classes, predicted_classes, average='micro')\n","recall_micro = recall_score(true_classes, predicted_classes, average='micro')\n","f1_micro = f1_score(true_classes, predicted_classes, average='micro')\n","\n","precision_weighted = precision_score(true_classes, predicted_classes, average='weighted')\n","recall_weighted = recall_score(true_classes, predicted_classes, average='weighted')\n","f1_weighted = f1_score(true_classes, predicted_classes, average='weighted')\n","\n","# Adding metrics to the results dataframe\n","results = {\n","    'Class': class_names,\n","    'Accuracy': [accuracy] * len(class_names),\n","    'Precision': precision,\n","    'Recall': recall,\n","    'F1 Score': f1\n","}\n","\n","# Create a Pandas DataFrame from the dictionary\n","df = pd.DataFrame(results)\n","\n","# Save the DataFrame to a CSV file\n","df.to_csv('results_1.csv', index=False)\n","\n","# Print overall evaluation metrics\n","print(f\"Accuracy: {accuracy:.4f}\")\n","for idx, class_name in enumerate(class_names):\n","    print(f\"Class: {class_name}\")\n","    print(f\"  Precision: {precision[idx]:.4f}\")\n","    print(f\"  Recall: {recall[idx]:.4f}\")\n","    print(f\"  F1 Score: {f1[idx]:.4f}\")\n","\n","# Print macro, micro, and weighted averages\n","print(\"\\nMacro Average Metrics:\")\n","print(f\"  Precision: {precision_macro:.4f}\")\n","print(f\"  Recall: {recall_macro:.4f}\")\n","print(f\"  F1 Score: {f1_macro:.4f}\")\n","\n","print(\"\\nMicro Average Metrics:\")\n","print(f\"  Precision: {precision_micro:.4f}\")\n","print(f\"  Recall: {recall_micro:.4f}\")\n","print(f\"  F1 Score: {f1_micro:.4f}\")\n","\n","print(\"\\nWeighted Average Metrics:\")\n","print(f\"  Precision: {precision_weighted:.4f}\")\n","print(f\"  Recall: {recall_weighted:.4f}\")\n","print(f\"  F1 Score: {f1_weighted:.4f}\")"],"metadata":{"id":"xluJ69Us903p"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb","timestamp":1718724768274}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}